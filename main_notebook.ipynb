{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import and process the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Class cap-shape cap-surface cap-color bruises? odor gill-attachment  \\\n",
      "0        p         x           s         n        t    p               f   \n",
      "1        e         x           s         y        t    a               f   \n",
      "2        e         b           s         w        t    l               f   \n",
      "3        p         x           y         w        t    p               f   \n",
      "4        e         x           s         g        f    n               f   \n",
      "...    ...       ...         ...       ...      ...  ...             ...   \n",
      "8119     e         k           s         n        f    n               a   \n",
      "8120     e         x           s         n        f    n               a   \n",
      "8121     e         f           s         n        f    n               a   \n",
      "8122     p         k           y         n        f    y               f   \n",
      "8123     e         x           s         n        f    n               a   \n",
      "\n",
      "     gill-spacing gill-size gill-color  ... stalk-surface-below-ring  \\\n",
      "0               c         n          k  ...                        s   \n",
      "1               c         b          k  ...                        s   \n",
      "2               c         b          n  ...                        s   \n",
      "3               c         n          n  ...                        s   \n",
      "4               w         b          k  ...                        s   \n",
      "...           ...       ...        ...  ...                      ...   \n",
      "8119            c         b          y  ...                        s   \n",
      "8120            c         b          y  ...                        s   \n",
      "8121            c         b          n  ...                        s   \n",
      "8122            c         n          b  ...                        k   \n",
      "8123            c         b          y  ...                        s   \n",
      "\n",
      "     stalk-color-above-ring stalk-color-below-ring veil-type veil-color  \\\n",
      "0                         w                      w         p          w   \n",
      "1                         w                      w         p          w   \n",
      "2                         w                      w         p          w   \n",
      "3                         w                      w         p          w   \n",
      "4                         w                      w         p          w   \n",
      "...                     ...                    ...       ...        ...   \n",
      "8119                      o                      o         p          o   \n",
      "8120                      o                      o         p          n   \n",
      "8121                      o                      o         p          o   \n",
      "8122                      w                      w         p          w   \n",
      "8123                      o                      o         p          o   \n",
      "\n",
      "     ring-number ring-type spore-print-color population habitat  \n",
      "0              o         p                 k          s       u  \n",
      "1              o         p                 n          n       g  \n",
      "2              o         p                 n          n       m  \n",
      "3              o         p                 k          s       u  \n",
      "4              o         e                 n          a       g  \n",
      "...          ...       ...               ...        ...     ...  \n",
      "8119           o         p                 b          c       l  \n",
      "8120           o         p                 b          v       l  \n",
      "8121           o         p                 b          c       l  \n",
      "8122           o         e                 w          v       l  \n",
      "8123           o         p                 o          c       l  \n",
      "\n",
      "[8124 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "columns = [\n",
    "    \"Class\", \"cap-shape\", \"cap-surface\", \"cap-color\", \"bruises?\", \"odor\",\n",
    "    \"gill-attachment\", \"gill-spacing\", \"gill-size\", \"gill-color\", \"stalk-shape\",\n",
    "    \"stalk-root\", \"stalk-surface-above-ring\", \"stalk-surface-below-ring\", \"stalk-color-above-ring\",\n",
    "    \"stalk-color-below-ring\", \"veil-type\", \"veil-color\", \"ring-number\", \"ring-type\",\n",
    "    \"spore-print-color\", \"population\", \"habitat\"\n",
    "    ]\n",
    "\n",
    "dataset = pd.read_csv(\"./src/agaricus-lepiota.data\", sep=\",\", names=columns)\n",
    "\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e\n"
     ]
    }
   ],
   "source": [
    "clases_values = {\"positive\": \"e\", \"negative\": \"p\"}\n",
    "\n",
    "print(clases_values[\"positive\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate positive and negative clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['p', 3916], ['e', 4208]]\n",
      "['p', 'e']\n",
      "[['p', 0.48202855736090594], ['e', 0.517971442639094]]\n"
     ]
    }
   ],
   "source": [
    "from homemaid_libs.OCAT.procesamiento_datasets import extraer_muestra, valores_observados, repeticiones_de_valor\n",
    "\n",
    "total_clases_original = []\n",
    "\n",
    "clases = valores_observados(dataset[\"Class\"].values)\n",
    "proporcion = []\n",
    "\n",
    "for clase in clases:\n",
    "    total = repeticiones_de_valor(clase, dataset[\"Class\"].values)\n",
    "    total_clases_original.append([clase, total])\n",
    "\n",
    "    proporcion.append([clase, total/len(dataset[\"Class\"].values)])\n",
    "\n",
    "print(total_clases_original)\n",
    "print(clases)\n",
    "print(proporcion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5686\n",
      "[['p', 2740], ['e', 2945]]\n",
      "['p', 2740]\n",
      "3916 3916\n",
      "['e', 2945]\n",
      "5384 5384\n",
      "column size: 22\n",
      "     cap-shape cap-surface cap-color bruises? odor gill-attachment  \\\n",
      "0            x           s         g        f    c               f   \n",
      "1            x           y         y        f    f               f   \n",
      "2            x           f         g        f    f               f   \n",
      "3            f           s         e        f    f               f   \n",
      "4            x           s         n        f    s               f   \n",
      "...        ...         ...       ...      ...  ...             ...   \n",
      "5680         k           s         w        f    n               f   \n",
      "5681         x           s         n        f    n               f   \n",
      "5682         x           f         n        f    n               f   \n",
      "5683         x           y         n        t    n               f   \n",
      "5684         f           y         y        t    a               f   \n",
      "\n",
      "     gill-spacing gill-size gill-color stalk-shape  ...  \\\n",
      "0               c         n          g           e  ...   \n",
      "1               c         b          h           e  ...   \n",
      "2               c         b          p           e  ...   \n",
      "3               c         n          b           t  ...   \n",
      "4               c         n          b           t  ...   \n",
      "...           ...       ...        ...         ...  ...   \n",
      "5680            w         b          p           e  ...   \n",
      "5681            w         b          p           t  ...   \n",
      "5682            w         b          k           t  ...   \n",
      "5683            c         b          p           t  ...   \n",
      "5684            c         b          n           e  ...   \n",
      "\n",
      "     stalk-color-above-ring stalk-color-below-ring veil-type veil-color  \\\n",
      "0                         w                      w         p          w   \n",
      "1                         n                      n         p          w   \n",
      "2                         p                      b         p          w   \n",
      "3                         w                      w         p          w   \n",
      "4                         p                      w         p          w   \n",
      "...                     ...                    ...       ...        ...   \n",
      "5680                      w                      w         p          w   \n",
      "5681                      w                      w         p          w   \n",
      "5682                      w                      w         p          w   \n",
      "5683                      w                      g         p          w   \n",
      "5684                      w                      w         p          w   \n",
      "\n",
      "     ring-number ring-type spore-print-color population habitat Class  \n",
      "0              o         p                 n          v       d     p  \n",
      "1              o         l                 h          v       d     p  \n",
      "2              o         l                 h          v       g     p  \n",
      "3              o         e                 w          v       p     p  \n",
      "4              o         e                 w          v       l     p  \n",
      "...          ...       ...               ...        ...     ...   ...  \n",
      "5680           t         p                 w          n       g     e  \n",
      "5681           o         e                 k          a       g     e  \n",
      "5682           o         e                 n          s       g     e  \n",
      "5683           o         p                 n          y       d     e  \n",
      "5684           o         p                 k          y       g     e  \n",
      "\n",
      "[5685 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "train, test = extraer_muestra(dataset.drop(\"Class\", axis=1), dataset[\"Class\"], proporcion, dataset.__len__(), 0.7)\n",
    "\n",
    "print(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Binarize our dataframe!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from homemaid_libs.OCAT.Binarizacion import binarizar_categoricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      x1,1  x1,2  x1,3  x1,4  x1,5  x1,6 valor_real 1  x2,1  x2,2  x2,3  ...  \\\n",
      "0        1     0     0     0     0     0            x     1     0     0  ...   \n",
      "1        1     0     0     0     0     0            x     0     1     0  ...   \n",
      "2        1     0     0     0     0     0            x     0     0     1  ...   \n",
      "3        0     1     0     0     0     0            f     1     0     0  ...   \n",
      "4        1     0     0     0     0     0            x     1     0     0  ...   \n",
      "...    ...   ...   ...   ...   ...   ...          ...   ...   ...   ...  ...   \n",
      "5680     0     0     1     0     0     0            k     1     0     0  ...   \n",
      "5681     1     0     0     0     0     0            x     1     0     0  ...   \n",
      "5682     1     0     0     0     0     0            x     0     0     1  ...   \n",
      "5683     1     0     0     0     0     0            x     0     1     0  ...   \n",
      "5684     0     1     0     0     0     0            f     0     1     0  ...   \n",
      "\n",
      "      valor_real 21 x22,1  x22,2  x22,3  x22,4  x22,5  x22,6  x22,7  \\\n",
      "0                 v     1      0      0      0      0      0      0   \n",
      "1                 v     1      0      0      0      0      0      0   \n",
      "2                 v     0      1      0      0      0      0      0   \n",
      "3                 v     0      0      1      0      0      0      0   \n",
      "4                 v     0      0      0      1      0      0      0   \n",
      "...             ...   ...    ...    ...    ...    ...    ...    ...   \n",
      "5680              n     0      1      0      0      0      0      0   \n",
      "5681              a     0      1      0      0      0      0      0   \n",
      "5682              s     0      1      0      0      0      0      0   \n",
      "5683              y     1      0      0      0      0      0      0   \n",
      "5684              y     0      1      0      0      0      0      0   \n",
      "\n",
      "      valor_real 22  Class  \n",
      "0                 d      p  \n",
      "1                 d      p  \n",
      "2                 g      p  \n",
      "3                 p      p  \n",
      "4                 l      p  \n",
      "...             ...    ...  \n",
      "5680              g      e  \n",
      "5681              g      e  \n",
      "5682              g      e  \n",
      "5683              d      e  \n",
      "5684              g      e  \n",
      "\n",
      "[5685 rows x 140 columns]\n"
     ]
    }
   ],
   "source": [
    "binarized_dataframe:list[pd.DataFrame] = []\n",
    "\n",
    "for i, label in enumerate(columns):\n",
    "    if i == 0: continue\n",
    "\n",
    "    binarized_dataframe.append(binarizar_categoricos(train[label].values.tolist(), i))\n",
    "\n",
    "#let's concatenate to our binarized dataframe the class value in order to know this value in furder progress\n",
    "binarized_dataframe.append(train[\"Class\"])\n",
    "binary_train = pd.concat(binarized_dataframe, axis=1)\n",
    "\n",
    "print(binary_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# positive_train = binary_train[binary_train[\"Class\"] == clases_values[\"positive\"]]\n",
    "# negative_train = binary_train[binary_train[\"Class\"] == clases_values[\"negative\"]]\n",
    "\n",
    "# print(positive_train)\n",
    "# print(negative_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time for the candidate elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "garbage:list[str] = []\n",
    "for i in range(1,23):\n",
    "    if i == 22:\n",
    "        garbage.append(f\"valor_real {i}\")\n",
    "    else:\n",
    "        garbage.append(f\"valor_real {i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117\n",
      "<*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*>\n",
      "<0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0>\n"
     ]
    }
   ],
   "source": [
    "#generamos las hipotesis general y especifica\n",
    "\n",
    "from homemaid_libs.Candidate_Elimination.hipotesis import General, Especifica as Specific, predicciones, probarHipotesis\n",
    "\n",
    "# import homemaid_libs.Candidate_Elimination.hipotesis as hypotesis\n",
    "\n",
    "\n",
    "#recordemos que no hablamos de hipotesis general y especifica como unicas hipoesis, sino mas bien nos referimos a un conjunto de hipotesis\n",
    "columns_without_class = binary_train.drop([\"Class\", *garbage], axis=1).columns.tolist()\n",
    "# columns_without_class.pop(len(columns_without_class)-1)\n",
    "general_hypotesis = [General(columns_without_class)]\n",
    "specific_hypotesis = [Specific(columns_without_class)]\n",
    "\n",
    "# print(corpus.columns)\n",
    "print(len(general_hypotesis[0].aceptados))\n",
    "print(general_hypotesis[0])\n",
    "print(specific_hypotesis[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from homemaid_libs.Candidate_Elimination.candidate_elimination import Candidate_Elimination\n",
    "\n",
    "general_hypotesis, specific_hypotesis = Candidate_Elimination(specific_hypotesis, general_hypotesis, binary_train.drop([\"Class\", *garbage], axis=1), binary_train[\"Class\"], clases_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "[[0, 1], [1, 0], [0, 1], [0, 1], [0], [0, 1], [0, 1], [1, 0], [0, 1], [0], [0, 1], [0, 1], [0, 1], [1, 0], [0, 1], [0, 1], [0, 1], [0, 1], [0, 1], [0, 1], [0, 1], [1, 0], [0], [0], [0], [0], [1, 0], [0], [0], [0, 1], [0, 1], [1, 0], [0, 1], [1, 0], [0, 1], [0, 1], [1, 0], [0, 1], [0, 1], [1, 0], [0], [0, 1], [0, 1], [0], [0, 1], [0, 1], [0, 1], [0, 1], [0, 1], [0, 1], [1, 0], [1, 0], [0, 1], [0, 1], [0, 1], [0, 1], [1, 0], [0, 1], [0, 1], [0, 1], [1, 0], [0, 1], [0, 1], [0, 1], [1, 0], [0, 1], [0, 1], [0], [0], [0], [0, 1], [0, 1], [0, 1], [0, 1], [0, 1], [0], [0, 1], [0], [0], [1, 0], [0, 1], [0, 1], [1], [1, 0], [0], [0, 1], [0, 1], [1, 0], [0, 1], [0], [1, 0], [0], [0, 1], [0], [0, 1], [1, 0], [0, 1], [0, 1], [0, 1], [0], [0, 1], [0, 1], [0, 1], [0, 1], [0, 1], [0, 1], [1, 0], [0, 1], [0, 1], [0, 1], [1, 0], [0, 1], [0, 1], [0, 1], [0, 1], [0, 1], [0, 1]]\n"
     ]
    }
   ],
   "source": [
    "print(len(specific_hypotesis.aceptados[1]))\n",
    "print(specific_hypotesis.aceptados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96\n"
     ]
    }
   ],
   "source": [
    "contador = 0\n",
    "for aceptados in specific_hypotesis.aceptados:\n",
    "    for aceptado in aceptados:\n",
    "        if aceptado == 1: contador +=1\n",
    "\n",
    "print(contador)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117\n",
      "<*, *, *, *, [0], *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *>\n"
     ]
    }
   ],
   "source": [
    "print(len(general_hypotesis[0].aceptados))\n",
    "print(general_hypotesis[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we can check our Hypotesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      x1,1  x1,2  x1,3  x1,4  x1,5  x1,6 valor_real 1  x2,1  x2,2  x2,3  ...  \\\n",
      "0        1     0     0     0     0     0            f     1     0     0  ...   \n",
      "1        0     1     0     0     0     0            x     0     1     0  ...   \n",
      "2        0     1     0     0     0     0            x     0     1     0  ...   \n",
      "3        0     1     0     0     0     0            x     1     0     0  ...   \n",
      "4        0     1     0     0     0     0            x     1     0     0  ...   \n",
      "...    ...   ...   ...   ...   ...   ...          ...   ...   ...   ...  ...   \n",
      "2434     0     1     0     0     0     0            x     1     0     0  ...   \n",
      "2435     0     0     0     1     0     0            k     1     0     0  ...   \n",
      "2436     0     1     0     0     0     0            x     1     0     0  ...   \n",
      "2437     1     0     0     0     0     0            f     1     0     0  ...   \n",
      "2438     0     1     0     0     0     0            x     1     0     0  ...   \n",
      "\n",
      "      valor_real 21 x22,1  x22,2  x22,3  x22,4  x22,5  x22,6  x22,7  \\\n",
      "0                 v     1      0      0      0      0      0      0   \n",
      "1                 s     1      0      0      0      0      0      0   \n",
      "2                 v     0      1      0      0      0      0      0   \n",
      "3                 v     0      1      0      0      0      0      0   \n",
      "4                 s     1      0      0      0      0      0      0   \n",
      "...             ...   ...    ...    ...    ...    ...    ...    ...   \n",
      "2434              v     0      0      0      0      1      0      0   \n",
      "2435              c     0      0      0      0      1      0      0   \n",
      "2436              v     0      0      0      0      1      0      0   \n",
      "2437              c     0      0      0      0      1      0      0   \n",
      "2438              c     0      0      0      0      1      0      0   \n",
      "\n",
      "      valor_real 22  Class  \n",
      "0                 g      p  \n",
      "1                 g      p  \n",
      "2                 u      p  \n",
      "3                 u      p  \n",
      "4                 g      p  \n",
      "...             ...    ...  \n",
      "2434              l      e  \n",
      "2435              l      e  \n",
      "2436              l      e  \n",
      "2437              l      e  \n",
      "2438              l      e  \n",
      "\n",
      "[2439 rows x 140 columns]\n"
     ]
    }
   ],
   "source": [
    "binarized_test_dataframe:list[pd.DataFrame] = []\n",
    "\n",
    "for i, label in enumerate(columns):\n",
    "    if i == 0: continue\n",
    "\n",
    "    binarized_test_dataframe.append(binarizar_categoricos(test[label].values.tolist(), i))\n",
    "\n",
    "#let's concatenate to our binarized dataframe the class value in order to know this value in furder progress\n",
    "binarized_test_dataframe.append(test[\"Class\"])\n",
    "binary_test = pd.concat(binarized_test_dataframe, axis=1)\n",
    "\n",
    "print(binary_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'p', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'p', 'e', 'e', 'e', 'e', 'p', 'e', 'p', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'p', 'e', 'p', 'p', 'e', 'p', 'p', 'e', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'e', 'p', 'p', 'p', 'p', 'p', 'e', 'p', 'e', 'p', 'e', 'e', 'p', 'p', 'p', 'p', 'p', 'e', 'p', 'p', 'p', 'p', 'e', 'p', 'e', 'p', 'e', 'e', 'p', 'p', 'e', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'e', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'e', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'e', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'e', 'p', 'e', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'e', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'e', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'e', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'e', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'e', 'p', 'p', 'p', 'p', 'p', 'p', 'e', 'p', 'e', 'p', 'e', 'p', 'e', 'e', 'p', 'p', 'p', 'p', 'p', 'p', 'e', 'p', 'e', 'p', 'p', 'e', 'e', 'e', 'p', 'e', 'e', 'p', 'p', 'p', 'e', 'p', 'p', 'p', 'e', 'p', 'e', 'e', 'p', 'p', 'p', 'p', 'e', 'p', 'e', 'p', 'p', 'p', 'p', 'p', 'e', 'e', 'p', 'e', 'e', 'p', 'p', 'p', 'e', 'e', 'e', 'e', 'p', 'p', 'p', 'p', 'p', 'e', 'p', 'e', 'e', 'e', 'p', 'p', 'p', 'e', 'p', 'e', 'p', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'p', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'p', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'p', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'p', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'p', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'p', 'p', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'p', 'p', 'p', 'e', 'e', 'e', 'e', 'e', 'p', 'p', 'e', 'e', 'e', 'e', 'p', 'e', 'p', 'p', 'e', 'e', 'e', 'p', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'p', 'e', 'p', 'e', 'p', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'p', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'p', 'e', 'p', 'e', 'e', 'e', 'e', 'p', 'e', 'p', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'p', 'p', 'e', 'p', 'p', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'p', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'p', 'p', 'e', 'p', 'p', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'p', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'p', 'e', 'e', 'p', 'p', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'p', 'e', 'p', 'e', 'p', 'p', 'e', 'e', 'e', 'p', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'p', 'e', 'p', 'e', 'e', 'p', 'p', 'p', 'e', 'p', 'e', 'e', 'e', 'p', 'e', 'p', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'p', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'p', 'e', 'e', 'e', 'p', 'e', 'e', 'p', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'p', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'p', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'p', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'p', 'p', 'p', 'e', 'p', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'p', 'p', 'e', 'p', 'e', 'p', 'p', 'e', 'e', 'p', 'p', 'e', 'e', 'p', 'e', 'e', 'e', 'p', 'e', 'p', 'p', 'e', 'e', 'p', 'e', 'e', 'p', 'e', 'e', 'e', 'p', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'p', 'p', 'p', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'p', 'p', 'e', 'e', 'e', 'e', 'p', 'p', 'p', 'p', 'e', 'e', 'p', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'p', 'e', 'e', 'e', 'p', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'p', 'e', 'p', 'e', 'p', 'p', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'p', 'p', 'e', 'e', 'e', 'p', 'e', 'p', 'e', 'e', 'p', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'p', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'p', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'p', 'p', 'p', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'p', 'p', 'p', 'e', 'e', 'e', 'e', 'p', 'p', 'e', 'e', 'e', 'p', 'p', 'e', 'e', 'p', 'e', 'e', 'e', 'p', 'p', 'p', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'p', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'p', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'p', 'p', 'e', 'e', 'p', 'p', 'e', 'e', 'e', 'p', 'p', 'e', 'e', 'e', 'e', 'e', 'p', 'p', 'p', 'e', 'e', 'p', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'p', 'p', 'e', 'e', 'p', 'e', 'p', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'p', 'e', 'p', 'p', 'e', 'p', 'p', 'p', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'p', 'e', 'e', 'p', 'p', 'e', 'p', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'p', 'e', 'e', 'p', 'e', 'p', 'e', 'e', 'p', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'p', 'e', 'e', 'e', 'e', 'p', 'e', 'p', 'e', 'e', 'p', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'p', 'e', 'e', 'e', 'p', 'p', 'e', 'e', 'e', 'p', 'e', 'e', 'p', 'e', 'p', 'p', 'p', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'p', 'p', 'p', 'p', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'p', 'p', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'p', 'p', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'p', 'p', 'p', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'p', 'e', 'p', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'p', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'p', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'p', 'e', 'p', 'e', 'e', 'p', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'p', 'e', 'p', 'p', 'p', 'e', 'p', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'p', 'p', 'p', 'p', 'e', 'e', 'e', 'p', 'p', 'e', 'p', 'e', 'p', 'e', 'p', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'p', 'p', 'e', 'e', 'p', 'e', 'e', 'p', 'e', 'p', 'p', 'p', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'p', 'e', 'e', 'e', 'p', 'e', 'p', 'e', 'e', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'e', 'e', 'e', 'e', 'e', 'p', 'p', 'p', 'e', 'e', 'e', 'e', 'p', 'e', 'p', 'p', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'p', 'e', 'p', 'e', 'p', 'p', 'p', 'p', 'p', 'e', 'e', 'e', 'p', 'p', 'e', 'e', 'e', 'e', 'p', 'p', 'p', 'e', 'e', 'e', 'p', 'p', 'p', 'p', 'e', 'e', 'e', 'p', 'p', 'e', 'e', 'e', 'e', 'p', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'p', 'e', 'p', 'e', 'e', 'p', 'e', 'e', 'e', 'p', 'e', 'e', 'p', 'e', 'p', 'e', 'p', 'e', 'e', 'e', 'p', 'p', 'e', 'e', 'e', 'p', 'e', 'e', 'p', 'p', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'p', 'e', 'e', 'e', 'e', 'p', 'e', 'p', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'p', 'p', 'p', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e']\n"
     ]
    }
   ],
   "source": [
    "prediction:list[str] = []\n",
    "\n",
    "binary_test_cleaned = binary_test.drop([\"Class\", *garbage], axis=1).values.tolist()\n",
    "\n",
    "for row in binary_test_cleaned:\n",
    "    prediction.append(predicciones(row, hipotesis_especifica=specific_hypotesis, asignacion=[\"e\", \"p\"]))\n",
    "\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vp: 1468\tfp: 314\n",
      "fn: 439\t vn: 218\n",
      "accuracy: 0.6912669126691267\n",
      "precision: 0.8237934904601572\n",
      "recall: 0.7697954902988988\n",
      "f1: 0.7958796421794524\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probarHipotesis(prediction, binary_test[\"Class\"], [\"e\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aprendisaje-simbolico-automatico",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
